{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## <center>基于UIE-X模型跨长文档级别的信息抽取案例教程 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " + <p>本项目采用UIE-X模型实现跨文档级别信息抽取，在少样本上进行微调，实现文档级别的端到端应用方案，打通长文档格式处理-数据标注-模型训练-模型调优-预测部署全流程，可快速实现文档信息抽取产品落地。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 跨文档处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 业务场景下的数据大多为非结构化的数据,如word文档(.docx)、excle文档(.xlsx)、PDF文档、jpg图片等。采用UIE-X模型需要统一化处理这些格式化形式。\n",
    "\n",
    "2. langchain框架集成多种非结构化文档处理形式，推荐使用 pip install langchain"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 加载langchain UnstructuredFileLoader 函数\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "\"\"\"\n",
    "TXT文档载入导入文本\n",
    "\"\"\"\n",
    "loader = UnstructuredFileLoader(\"./example_data/state_of_the_union.txt\")\n",
    "document = loader.load()\n",
    "print(docs[0].page_content)\n",
    "\"\"\"\n",
    "DOCX文档读入(word)\n",
    "\"\"\"\n",
    "loader = UnstructuredWordDocumentLoader(\"example_data/fake.docx\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 将长文本切分若干个segment篇落\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\"实例化对象:每个篇落 chunk_size 字符，片落前后重叠为 chunk_overlop\"\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500 , chunk_overlap = 100)\n",
    "\"document 是 Document实例化对象\"\n",
    "split_document = text_splitter.split_documents(document)\n",
    "\"document 是字符串\"\n",
    "split_document = text_splitter.create_documents([document])\n",
    "# 遍历文档：\n",
    "for d  in split_document:\n",
    "    print(d.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据正则模式标注"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.UIEX模型依赖百度Label_Studio标注平台，会生成label_studio.json文件，经DataConverter转化成训练集和验证集。\n",
    "\n",
    "2.针对用户私有化的数据，为避免数据泄露，自己提出一种数据标注方案，完全不用依赖label_studio。 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "1. 在公开数据集tax上分析label_studio平台的标注模式\n",
    "\n",
    "tax_data_file = './tax/train.txt'\n",
    "tax_data = open(tax_data_file,'r' encoding = 'utf-8').read()\n",
    "tax_data = tax_data.strip().split('\\n')\n",
    "# 分析某一个样本   tax_one  = eval(tax_data[0])\n",
    "# tax_one 字典形式存放，keys 有 content \\ result_list \\ prompt \\ image\\ bbox\n",
    "# 查看result_list 键值; 存放着 text / start / end \n",
    "\n",
    "\n",
    "2.标注模式：    \n",
    "      UIEX模型采用 pointer_based 标注模式，既标注待提取短语的首位起始位置；\n",
    "      UIEX模型并不是论文上所述的方法（text2structured）,是 基座模型是ERNIE_layout + mrc 方法            \n",
    "\n",
    "      构造标注的难点：\n",
    "         在于怎么准确找到start end 的 ids 信息，查看paddle源码，只需找到 target 分词id 在文本中的id 的位置信息即可。\n",
    "\n",
    "\n",
    "3. 设计自己的标注方法：\n",
    "\n",
    "   标注样例：\n",
    "    \n",
    "   content：str              #   输入word 文档 转换 长字符串篇落\n",
    "   \n",
    "   label：{ prompt ： target }    #   prompt 提示短语  target 待提取的标注短语，target短语在content文本中出现，\n",
    "                            target 提取短语句子较长，且存在控制符、换行符等，通过正则的方法进行标注。\n",
    "                                   \n",
    "   \n",
    "\n",
    "eg： 采用正则模式进行标注，减少target的格式与word 文档里 content 不一致现象；\n",
    "content = '小明的公民身份证号：[99322], 年龄：ddd '\n",
    "label = {'身份证号'：\"[./d*?]\"}  \n",
    "# label形式为： {prompt ： target}\n",
    "import re\n",
    "def search(pattern,sequences):\n",
    "     target = re.search(pattern,sequences)\n",
    "     if target:\n",
    "        return target.group(0)\n",
    "     else:\n",
    "        return -1\n",
    "# 通过这种方法，就可以将文档中出现的target 的跨度提取出来\n",
    "example = {'content' : content, 'result_list':[{'text': 99322, 'start': None ,'end' : None }],\"prompt\" : '身份证号'}\n",
    "\n",
    "\n",
    "\n",
    "4. 构造UIEX模型的输入形式\n",
    "   正则的方法将target的内容取出来，保存在example[\"result_list\"][0]['text']里 ，\n",
    "   接着需要确定 result_list 里 start 、end 首尾位置 id 位置信息；\n",
    "\n",
    "encoded_inputs = tokenizer(\n",
    "                 text = [example['prompt']],\n",
    "                 text_pair = [example['content']],\n",
    "                 ...,\n",
    "                 ...\n",
    ")\n",
    "# UIEX 输入形式： cls  prompt  sep  sep content sep\n",
    "input_ids = encoded_inputs['input_ids']\n",
    "# 找 text 文本分词后在 input_ids 所对应的首尾位置id\n",
    "text_ids = tokenizer(text)[1:-1]\n",
    "def search_id(text_ids,input_ids):\n",
    "    n = len(text_ids)\n",
    "    for i in range(len(input_ids):\n",
    "        if input_ids[i:i + n ] == text_ids:\n",
    "                   return i \n",
    "    else:\n",
    "                   return -1\n",
    "    \n",
    "start = search_id(text_ids,input_ids)\n",
    "if start != -1:                   \n",
    "    end = start + len(text_ids) - 1\n",
    "# 这样就能得到 start end id信息，填入上述example['result_list'] ，就可以完成构造样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 总结：\n",
    "   1. 正则模式标注待提取target的span跨度；\n",
    "   2. 分别对文档和target 进行分词处理，文档：input_ids， target：text_ids \n",
    "     text_ids 在 input_ids 序列中，确定start end 的首尾 id值 \n",
    "   3. 转换UIEX模型所需的样本example形式；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 官方tax案例微调代码：https://github.com/PaddlePaddle/PaddleNLP/blob/develop/applications/information_extraction/document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推理测试"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. 第一种方案：\n",
    "   Taskflow ： 当schema待提取数量集合过多时，调用 Taskflow 运行性能低，很耗时；\n",
    "2. 第二种方案： 调用 底座模型 ERNIE_layout 模型\n",
    "   model = UIEX.from_pretrained(checkpoint)\n",
    "   for batch in infer_data_loader:\n",
    "      start_prob , end_prob = model(**batch)  \n",
    "实验证实：直接调用底座模型，推理速度更快"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
