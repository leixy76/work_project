## 模型训练

在技术性标书生成过程中，主要面临两大挑战：首先，标题通常简短且信息有限，导致从相关文件中难以检索到足够的信息；其次，如何基于检索到的内容生成详细且连贯的长段落输出。针对这些难点，可以考虑以下优化方案：

**1. 标题简短、信息有限的问题**

​		*指令扩展*：根据标题进行问题拓展，大模型可以预测用户可能期待的指令，该指令通过限制写作方向来使内容更加具体，从而对标题进行有效扩展。

​		*模块化检索*：不依赖语义匹配，仅通过大模型判断当前段落与指令的相关性,请参考个人项目。

**2. 增强长段落输出的问题**

​   *微调模型*：为了生成详细且连贯的长段落输出，微调模型具有长文本输出的能力。

#### **数据准备**

首先，使用`llama_index`对文件进行解析，`llama-hub`提供了多种文件格式的解析支持。解析后的文件将以句子为粒度进行分块。接着，对每个分块数据分别执行清洗和筛选操作（基于`neo`开源项目的代码），以确保数据的高质量，从而为后续的模型训练提供优质的输入数据。

+ **数据清洗**
  该函数用于对输入文本进行格式统一和清洗操作，确保文本符合特定的格式要求。该函数用于从文本中移除 URL 链接，确保文本中不包含任何形式的 URL。

  1. *中文括号检测与比例计算*
  2. *全角符号转半角符号*

  3. *移除常见 URL*

+ **数据筛选**

  主要实现了三个功能模块，分别用于根据自定义规则、`CCNet`规则和重复内容规则对文本进行过滤和验证。以下是每个模块的主要功能总结：

  1. *自定义规则过滤*： 句子数量、平均词长、 数字词比例、 ......

  2. *CCNet规则过滤*： 语言识别模型评分

  3. *重复内容规则过滤* ：n-gram重复字符比例: 

+ **数据构造流程**

  `Self-instruct`是一种用于生成指令数据的方法,通过模型自身生成指令和相应的输入-输出对，从而构建一个大规模的、多样化的数据集。为了使生成的指令更具针对性，可以引入标题等元数据信息，以进一步增强指令的精确性和实用性。

  ```mermaid
  graph LR
      A[解析文件] --> B[粒度分块]
      B --> C[数据清洗]
      C --> D[数据过滤]
      D --> E[数据筛选]
      E --> F[标题提取]
      F --> G[问题生成]
      G --> H[问题回答]
  ```
  参考样本示例  
  ```python
      {
          "instruction": "1: 文档中提到的主要法律法规有哪些，并列举至少两种？\n2: 文档中的标准规范部分提到了哪些具体标准？请至少列举三个。\n3: 在文中提到的各单位中，主要有哪些单位参与其中？请至少列举四个。",
          "title": "工程安全管理与规范综合方案及相关单位职责说明",
          "content": "中华人民共和国安全生产法(国家主席令第 70号)......"
      },
  ```
